<html>
    <head>
        <meta http-equiv="content-type" content="text/html; charset=utf-8" />
        <link href="http://www.templex.xyz/main.css" rel="stylesheet" type="text/css">
        <link rel="alternate" type="application/atom+xml" href="/atom.xml" title="Atom feed">
        <link rel="shortcut icon" href="http://www.templex.xyz/images/3x3.jpg">
        <title>设计高可靠的存储系统</title>
</head>
<body>
    <h2>设计高可靠的存储系统</h2>
    <p>在数据量很大的情况下，大部分时候我们会选择机械磁盘作为载体，然而磁盘并不是100%可靠的。甚至远远
        比我们想象的还要更不可靠，大家可以参考
        <a href="https://www.backblaze.com">Backblaze</a>
        提供的数据。</p>
    <p>有很多公司声称解决了这个问题，其实思路并不复杂：</p>
    <ol>
    <li>降低故障率</li>
    <p>意味着使用质量更好的硬件。关于这一点这里就不讨论了</p>
    <li>降低猝死的概率</li>
    <p>意味着使用冗余策略,比如副本或者Erasure Codes</p>
    <li>提高修复速度</li>
    <p>意味着更有机会“起死回生”</p>
    </ol>
    <h3>冗余</h3>
    <p>单从可靠性上来讲，纠删码能实现同等成本、空间条件下相对于副本方案倍数级别的提升。不过工程上会有些麻烦，
        大方向上是很简单的，主要是一些细节的调整。
        Reed Solomon codes是门非常古老而且成熟的技术，在拿到实测数据之前，
        不要相信小厂对于自己纠删码吞方案在吞吐性能上的吹嘘。而且对于像Intel的ISA-L这样的高性能库来说，GB/S级别的吞吐已经完全足够了。
        纠删码相对于副本来说的主要麻烦之一就是，纠删码的写入需要计算。当我们要读取某一“丢失”文件时，就会有延迟。
        如果对这个延迟比较敏感，但又想进一步提高可靠性，我建议使用副本和纠删码混合部署的策略，其中冷数据落纠删码集群。
    </p>
    <h3>修复</h3>
    <p>修复速度的提高从两个方面入手：</p>
    <ol>
    <li>减少修复所需的数据量</li>
    <li>增加参与修复的磁盘数量</li>
    </ol>
    <p>第一点主要针对于EC，其中Facebook Azure都使用了改良版本的RS codes。
    </p>
    <p>第二点指的是并行修复。并行修复主要是为了应对单盘外部IO的瓶颈，但同时给了数据库和内部网络更大的压力。
        尤其是数据库的压力可能直接导致“丢数据”。所以我不建议并行修复的scope直接指定为全局。
    </p>
    <h3>向左走向右走</h3>
    <p>不难发现，设计高可靠的存储系统基本是在诸多成熟方案中做出选择，最终的可靠性取决于这套组合拳的配合程度。
        虽然这里仅有寥寥几百字，但都是很多光鲜亮丽的公司在这上面栽过的跟头
    </p>
        </body>
    </html>
